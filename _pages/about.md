---
permalink: /
title: "Personal Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Hello everyone, and welcome to my personal bio!  

I completed my undergraduate studies at the **University of Michigan**, where I earned my **B.S. in Data Science** (Go Blue!).  
Currently, I am pursuing a **Master of Science in Data Science** at the **University of Chicago**, under the **Data Science Institute (DSI)**.  

During my time here, I have had the opportunity to work with incredible faculty and collaborators, including [**Prof. James Evans**](https://sociology.uchicago.edu/directory/James-A-Evans) at the [Knowledge Lab](https://knowledgelab.org/), [**Prof. Zhewei Sun**](https://zhewei-sun.github.io/) in the [Speech and Language Group](https://slattic.ttic.edu/) at the [Toyota Technological Institute at Chicago (TTIC)](https://www.ttic.edu/), [**Prof. Ari Holtzman**](https://ariholtzman.com/) at the [Conceptualization Lab](https://conceptualization.ai/), and [**Prof. Bryon Aragam**](https://bryonaragam.com/) at the [Booth School of Business](https://www.chicagobooth.edu/).
 

### Research Interests

My research interests revolve around developing **principled frameworks to understand and evaluate large language models (LLMs)**—not just by their accuracy, but by what they *know*, *how* they reason, and *why* they fail. I aim to connect **behavioral reliability**, **semantic generalization**, and **social interpretation** in model evaluation.  

Broadly, my work focuses on:  
- **Credibility and Calibration:** Designing behavioral metrics that quantify the *credibility gap* between perturbed and unperturbed model states, bridging black-box reliability with internal reasoning stability.  
- **Benchmark Semantics and Meta-Evaluation:** Analyzing *benchmark overlap* and *perplexity signatures* to uncover what benchmarks truly measure and how model families internalize shared linguistic functions.  
- **Language and Society:** Using LLMs as scientific instruments to surface tacit human norms and evaluative heuristics—the “unwritten code” underlying peer review, storytelling, and cultural reasoning.  
- **Creative and Informal Language:** Investigating how models generate and reuse slang and informal expressions to assess their linguistic creativity, coherence, and informativeness.  

My broader goal is to advance **AI for Science (AI4Sci)** by building interpretable evaluation pipelines that link statistical robustness with scientific and social understanding.


### Open to Collaborations

I am always open to collaborations! If you have an interesting or early-stage idea—even a naïve one—let’s discuss it and see how we can turn it into something impactful together.

