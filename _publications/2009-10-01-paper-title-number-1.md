---
title: "Automatically Advancing LLM Expertise in Technology Judgment"
collection: publications
category: conferences
permalink: /publication/2025-05-20-advancing-llm-expertise
excerpt: "We introduce a large-scale benchmark evaluating how language models discern subtle conceptual distinctions between semantically similar inventions, revealing mechanisms of knowledge use and self-questioning in LLMs."
date: 2025-05-20
venue: "arXiv preprint"
paperurl: "https://arxiv.org/abs/2505.12452"
citation: 'Siyang Wu, H. Bao, N. Kunievsky, and James A. Evans. (2025). <i>Automatically Advancing LLM Expertise in Technology Judgment.</i> arXiv:2505.12452.'
---

This paper introduces a **novel patent differentiation benchmark** of 1.3M post-2015 computer science patents to evaluate how LLMs distinguish between semantically similar inventions.  
We develop a **self-questioning framework** that decomposes model errors into *missing* versus *unused* knowledge and show that structured introspective questioning can significantly improve conceptual reasoning in smaller and larger models alike.
